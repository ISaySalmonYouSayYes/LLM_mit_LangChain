{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1VUpE5RlmejGlFhjOUO15",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ISaySalmonYouSayYes/LLM_mit_LangChain/blob/main/LLM_Agent_Simulate_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **0. Before you start**  \n",
        "- Contents is always your best friend:P"
      ],
      "metadata": {
        "id": "mLuZ4f4xaX5h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiGADgqrXT02"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# OpenAI Secrets\n",
        "if COLAB:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('openAI_Key')\n",
        "\n",
        "# Install needed libraries in CoLab\n",
        "if COLAB:\n",
        "    !pip install langchain langchain_openai\n",
        "    !pip install langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. GPT-related method**  \n",
        "- Using GPT4.0-mini mit Langchain(A library uniforms the syntax of all LLMs)\n",
        "- Generating Persona(Characters) by LLM\n",
        "  - Few-shot learning\n",
        "  - Work perfectly with this prompt"
      ],
      "metadata": {
        "id": "EpfHIbuCau-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_core.prompts.chat import PromptTemplate\n",
        "\n",
        "def temp_sleep(seconds=0.1):\n",
        "  \"\"\"\n",
        "  Simulate the realistic delay\n",
        "  \"\"\"\n",
        "  time.sleep(seconds)\n",
        "\n",
        "def GPT4_request(prompt:str):\n",
        "  \"\"\"\n",
        "  Given a prompt, make a request to OpenAI server and returns the response.\n",
        "  ARGS:\n",
        "    prompt: a str prompt\n",
        "  RETURNS:\n",
        "    a str of GPT-4's response.\n",
        "  \"\"\"\n",
        "  MODEL = 'gpt-4o-mini'\n",
        "  messages = [\n",
        "    SystemMessage(content=\"user\"),\n",
        "    HumanMessage(content= prompt),\n",
        "    ]\n",
        "\n",
        "  llm = ChatOpenAI(\n",
        "    model=MODEL,\n",
        "    temperature= 0.0,\n",
        "    n= 1,\n",
        "    max_tokens= 256)\n",
        "\n",
        "  return llm.invoke(messages).content\n",
        "\n",
        "def GPT4_generate_persona(name:str):\n",
        "  MODEL = 'gpt-4o-mini'\n",
        "  prompt = f\"\"\"\n",
        "  Please creating information for {name} following the persona template. Don't add extra words.\n",
        "\n",
        "  ----------------------------------------\n",
        "  Template:\n",
        "      name (str): The name of the persona.\n",
        "      age (int): Age of the persona.\n",
        "      gender (str): Gender of the persona.\n",
        "      status (str): Occupation or current status.\n",
        "      hobbies (list): List of hobbies the persona enjoys.\n",
        "      wealth (int): Wealth level (0 to 1000).\n",
        "      favorite_food (str): Persona's favorite food.\n",
        "      nemesis (str or None): Persona's nemesis, if any.\n",
        "      quirky_trait (str or None): A quirky personality trait.\n",
        "  ----------------------------------------\n",
        "  Example:\n",
        "        name=\"Alex\",\n",
        "        age=29,\n",
        "        gender=\"Male\",\n",
        "        status=\"Freelance Illustrator\",\n",
        "        hobbies=[\"painting\", \"cycling\", \"reading sci-fi\"],\n",
        "        wealth=550,\n",
        "        favorite_food=\"Sushi\",\n",
        "        nemesis=\"Karen from accounting\",\n",
        "        quirky_trait=\"always wearing mismatched socks\"\n",
        "\n",
        "        name=\"Jill\",\n",
        "        age=27,\n",
        "        gender=\"Female\",\n",
        "        status=\"Software Developer\",\n",
        "        hobbies=[\"hiking\", \"playing video games\", \"cooking\"],\n",
        "        wealth=600,\n",
        "        favorite_food=\"Tacos\",\n",
        "        nemesis=\"The bug in her code\",\n",
        "        quirky_trait=\"collects vintage keychains\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  messages = [\n",
        "    SystemMessage(content=\"You're a system creating a simulated person\"),\n",
        "    HumanMessage(content= prompt),\n",
        "    ]\n",
        "\n",
        "  llm = ChatOpenAI(\n",
        "    model=MODEL,\n",
        "    temperature= 0.3,\n",
        "    n= 1,\n",
        "    max_tokens= 256)\n",
        "\n",
        "  return llm.invoke(messages).content\n",
        "\n",
        "\n",
        "#Debug ---- remove content in return line to see metadata\n",
        "# print(GPT4_request(\"Hiii, what is your name?\"))"
      ],
      "metadata": {
        "id": "qg3SEvhtXUdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Persona**\n",
        "- Create an object Persona documenting the personal info\n",
        "- Generating Persona(Characters) by LLM\n",
        "  - Few-shot learning\n",
        "  - Work perfectly with this prompt"
      ],
      "metadata": {
        "id": "jZc8aCh3p5gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Persona:\n",
        "    def __init__(self, name, age, gender, status, hobbies, wealth, favorite_food=\"Pizza\", nemesis=None, quirky_trait=None):\n",
        "        \"\"\"\n",
        "        Initializes a Persona instance with a mix of essential and fun attributes.\n",
        "\n",
        "        Args:\n",
        "            name (str): The name of the persona.\n",
        "            age (int): Age of the persona.\n",
        "            gender (str): Gender of the persona.\n",
        "            status (str): Occupation or current status.\n",
        "            hobbies (list): List of hobbies the persona enjoys.\n",
        "            wealth (int): Wealth level (0 to 1000).\n",
        "            favorite_food (str): Persona's favorite food (default is \"Pizza\").\n",
        "            nemesis (str or None): Persona's nemesis, if any.\n",
        "            quirky_trait (str or None): A quirky personality trait.\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.age = age\n",
        "        self.gender = gender\n",
        "        self.status = status\n",
        "        self.hobbies = hobbies\n",
        "        self.wealth = max(0, min(wealth, 1000))  # Clamped between 0 and 1000\n",
        "        self.favorite_food = favorite_food\n",
        "        self.nemesis = nemesis\n",
        "        self.quirky_trait = quirky_trait\n",
        "\n",
        "    def generate_persona_from_gpt(name:str):\n",
        "      gpt_response = GPT4_generate_persona(name)\n",
        "      persona_args = eval(f\"dict({gpt_response})\")\n",
        "      return Persona(**persona_args)\n",
        "\n",
        "    def display_info(self):\n",
        "        \"\"\"Displays basic information about the persona.\"\"\"\n",
        "        print(f\"Name: {self.name}\")\n",
        "        print(f\"Age: {self.age}\")\n",
        "        print(f\"Gender: {self.gender}\")\n",
        "        print(f\"Status: {self.status}\")\n",
        "        print(f\"Hobbies: {', '.join(self.hobbies)}\")\n",
        "        print(f\"Wealth: {self.wealth}\")\n",
        "        print(f\"Favorite Food: {self.favorite_food}\")\n",
        "        print(f\"Nemesis: {self.nemesis}\")\n",
        "        print(f\"Quirky Trait: {self.quirky_trait}\")\n",
        "\n",
        "    def info_to_dict(self):\n",
        "      \"\"\"Returns a dictionary containing the persona's attributes.\"\"\"\n",
        "      return {\n",
        "          \"name\": self.name,\n",
        "          \"age\": self.age,\n",
        "          \"gender\": self.gender,\n",
        "          \"status\": self.status,\n",
        "          \"hobbies\": self.hobbies,\n",
        "          \"wealth\": self.wealth,\n",
        "          \"favorite_food\": self.favorite_food,\n",
        "          \"nemesis\": self.nemesis,\n",
        "          \"quirky_trait\": self.quirky_trait,\n",
        "      }\n",
        "\n",
        "    def info_to_string_story(self):\n",
        "      return f'I am {self.name}. My age is {self.age}. My gender is {self.gender}. My status is {self.status}. My hobbies are {self.hobbies}.\\\n",
        "      My wealth is {self.wealth}. My Favorite food is {self.favorite_food}. My nemesis is {self.nemesis}. My Quirky Trait is {self.quirky_trait}'\n",
        "\n",
        "    def upgrade_wealth(self, amount):\n",
        "      \"\"\"\n",
        "      Increases the persona's wealth by a specified amount, ensuring it stays within the range of 0 to 1000.\n",
        "\n",
        "      Args:\n",
        "          amount (int): The amount to add to the persona's wealth.\n",
        "\n",
        "      Returns:\n",
        "          None\n",
        "      \"\"\"\n",
        "      if amount < 0:\n",
        "          print(f\"Cannot upgrade wealth by a negative amount: {amount}\")\n",
        "          return\n",
        "      previous_wealth = self.wealth\n",
        "      self.wealth = min(self.wealth + amount, 1000)"
      ],
      "metadata": {
        "id": "MA0skNv-sq8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Two AI talk to each other**"
      ],
      "metadata": {
        "id": "IOLjJBq97owK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationSummaryBufferMemory\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_core.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        ")\n",
        "from IPython.display import display_markdown\n",
        "\n",
        "\n",
        "def begin_conversation(persona_name, opposite_persona_name, persona_info, opposite_persona_info):\n",
        "    MODEL = 'gpt-4o-mini'\n",
        "\n",
        "    system_message = (\n",
        "    f\"You are {persona_name}. Here is your background:\\n\"\n",
        "    f\"{persona_info}\\n\\n\"\n",
        "    f\"You are speaking with {opposite_persona_name}, whose background is:\\n\"\n",
        "    f\"{opposite_persona_info}\\n\\n\"\n",
        "    \"Guidelines:\\n\"\n",
        "    \"1. Format answers with markdown.\\n\"\n",
        "    \"2. Answer based on the background information provided.\\n\"\n",
        "    f\"3. Repeat your name before answering (e.g., \\\"{persona_name}: ...\\\").\\n\"\n",
        "    \"4. Stick to the original topic.\\n\"\n",
        "    \"5. Avoid repeating yourself.\\n\")\n",
        "\n",
        "\n",
        "    # Create system and human message templates\n",
        "    system_message_template = SystemMessagePromptTemplate.from_template(\n",
        "        system_message\n",
        "    )\n",
        "\n",
        "\n",
        "    human_message_template = HumanMessagePromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        Conversation: {history}\n",
        "        Human: {input}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Combine into a ChatPromptTemplate\n",
        "    prompt_template = ChatPromptTemplate.from_messages(\n",
        "        [system_message_template, human_message_template]\n",
        "    )\n",
        "\n",
        "    # Initialize the OpenAI LLM\n",
        "    llm = ChatOpenAI(\n",
        "        model=MODEL,\n",
        "        temperature=0.0,\n",
        "        n=1,\n",
        "        max_tokens= 100\n",
        "    )\n",
        "\n",
        "    # Initialize memory with auto-summarization\n",
        "    memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=300)\n",
        "\n",
        "    # Build a conversation chain\n",
        "    conversation = ConversationChain(\n",
        "        prompt=prompt_template,\n",
        "        llm=llm,\n",
        "        memory=memory,\n",
        "        verbose=False,\n",
        "    )\n",
        "\n",
        "    return conversation\n",
        "\n",
        "\n",
        "def chat(conversation, prompt, name):\n",
        "    \"\"\"\n",
        "    Simulate a single conversational turn.\n",
        "\n",
        "    Args:\n",
        "        conversation: The ConversationChain object.\n",
        "        prompt (str): The message from the human.\n",
        "        name (str): The name of the persona responding.\n",
        "\n",
        "    Returns:\n",
        "        str: The AI's response.\n",
        "    \"\"\"\n",
        "    # Pass the prompt to the conversation chain\n",
        "    response = conversation.invoke({\"input\": prompt})\n",
        "    response_text = response['response']\n",
        "\n",
        "    # Display the response in markdown\n",
        "    display_markdown(f\"{response_text}\", raw=True)\n",
        "    return response_text\n",
        "\n",
        "\n",
        "def persona_to_persona_chat(persona_1_name, persona_2_name, persona_1_info, persona_2_info, persona_2_intro, rounds=5):\n",
        "    \"\"\"\n",
        "    Simulates a conversation between two personas using ConversationChain.\n",
        "\n",
        "    Args:\n",
        "        persona_1_name (str): The name of the first persona.\n",
        "        persona_2_name (str): The name of the second persona.\n",
        "        persona_2_intro (str): The introductory message from Persona 2.\n",
        "        rounds (int): Number of conversational exchanges.\n",
        "    \"\"\"\n",
        "    # Initialize two separate conversations for each persona\n",
        "    persona_1_conversation = begin_conversation(persona_1_name, persona_2_name, persona_1_info, persona_2_info)\n",
        "    persona_2_conversation = begin_conversation(persona_2_name, persona_1_name, persona_2_info, persona_1_info)\n",
        "\n",
        "    persona_2_intro = f\"{persona_2_name}: {persona_2_intro}.\"\n",
        "\n",
        "    # Start the conversation\n",
        "    print(\"=== Conversation Start ===\")\n",
        "    persona_1_response = chat(persona_1_conversation, persona_2_intro, persona_1_name)\n",
        "\n",
        "    # persona_1_response = f\"{persona_2_name}: {persona_2_intro}\\n {persona_1_response}\"\n",
        "    persona_1_response = f\"{persona_2_name}: {persona_2_intro}\\n {persona_1_name}: {persona_1_response}.\"\n",
        "    for i in range(rounds):\n",
        "        persona_2_response = chat(persona_2_conversation, persona_1_response, persona_2_name)\n",
        "        persona_1_response = chat(persona_1_conversation, persona_2_response, persona_1_name)\n",
        "    print(\"=== Conversation End ===\")\n"
      ],
      "metadata": {
        "id": "QiE0R-9vZ4-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Run here!**"
      ],
      "metadata": {
        "id": "J8gbNoZs8A1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persona_lea = Persona.generate_persona_from_gpt(\"Lea\")\n",
        "persona_alex = Persona(\n",
        "    name=\"Alex\",\n",
        "    age=29,\n",
        "    gender=\"Male\",\n",
        "    status=\"Freelance Illustrator\",\n",
        "    hobbies=[\"painting\", \"cycling\", \"reading sci-fi\"],\n",
        "    wealth=550,\n",
        "    favorite_food=\"Sushi\",\n",
        "    nemesis=\"Karen from accounting\",\n",
        "    quirky_trait=\"always wearing mismatched socks\"\n",
        ")\n",
        "Persona.display_info(persona_lea)"
      ],
      "metadata": {
        "id": "DSaC0AAVxtUm",
        "outputId": "cb9d6322-6dd5-43d7-a09e-d71d4383cd2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Lea\n",
            "Age: 32\n",
            "Gender: Female\n",
            "Status: Graphic Designer\n",
            "Hobbies: photography, traveling, yoga\n",
            "Wealth: 450\n",
            "Favorite Food: Pasta\n",
            "Nemesis: The printer that never works\n",
            "Quirky Trait: talks to her plants\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1 Case 1: Asking Alex to provide more money than he has**"
      ],
      "metadata": {
        "id": "Wz1yA8Xr8nY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define persona information\n",
        "persona_1_name = \"Alex\"\n",
        "persona_2_name = \"Lea\"\n",
        "persona_2_intro = \"Can I borrow 1000 from you?\"\n",
        "persona_2_info = persona_lea.info_to_string_story()\n",
        "persona_1_info = persona_alex.info_to_string_story()\n",
        "\n",
        "# Simulate their conversation\n",
        "persona_to_persona_chat(persona_1_name, persona_2_name, persona_1_info, persona_2_info, persona_2_intro, rounds=2)\n",
        "# persona_to_persona_chat(persona_1_name, persona_2_name, persona_2_intro, rounds=5)"
      ],
      "metadata": {
        "id": "DJciKHlKjYPO",
        "outputId": "41a8724f-4fce-4d6b-c048-5000244e9afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Conversation Start ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Alex: I wish I could help, but my wealth is only 550 right now. Maybe we can brainstorm some other ways to get you the funds you need?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Lea: I appreciate the offer, Alex! Maybe we could think about some freelance projects together or even sell some of our artwork online. What do you think?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Alex: That sounds like a great idea, Lea! Collaborating on freelance projects could definitely help us both out financially. Plus, selling our artwork online could reach a wider audience. Do you have any specific ideas in mind for the projects?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Lea: I'm glad you like the idea, Alex! I was thinking we could create a series of themed illustrations that combine your painting style with my graphic design skills. We could also consider making some prints or merchandise featuring our artwork. What themes do you think would resonate with people?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Alex: I love that concept, Lea! Combining our styles could create something really unique. As for themes, how about exploring sci-fi elements since I enjoy reading it? We could also consider nature themes, which could tie in nicely with your photography. What do you think?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Conversation End ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.2 Borrow reasonable money from Alex**"
      ],
      "metadata": {
        "id": "HF2GvM6N8vIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define persona information\n",
        "persona_1_name = \"Alex\"\n",
        "persona_2_name = \"Lea\"\n",
        "persona_2_intro = \"Can I borrow 20 from you?\"\n",
        "persona_2_info = persona_lea.info_to_string_story()\n",
        "persona_1_info = persona_alex.info_to_string_story()\n",
        "\n",
        "# Simulate their conversation\n",
        "persona_to_persona_chat(persona_1_name, persona_2_name, persona_1_info, persona_2_info, persona_2_intro, rounds=2)"
      ],
      "metadata": {
        "id": "K1ptqSEY8-x2",
        "outputId": "401ebe56-51ec-4bf4-bf36-59382ed27183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Conversation Start ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Alex: Sure, Lea! I can lend you 20. Just let me know when you can pay me back."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Lea: Thanks, Alex! I appreciate it. I'll make sure to pay you back soon. Maybe after my next freelance project wraps up!"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Alex: No problem, Lea! I'm glad to help. Good luck with your freelance project! If you need any tips or ideas, feel free to ask."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Lea: Thanks, Alex! I really appreciate your support. I might take you up on that offer for tips. Your illustrations are always so inspiring!"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Alex: Thanks, Lea! That means a lot to me. I'm always happy to share ideas or techniques. If you ever want to collaborate or brainstorm, just let me know!"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Conversation End ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **98. What to do next**"
      ],
      "metadata": {
        "id": "Wmp01CKiDSMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Retrieve new info from a conversation, and then upgrade the Persona."
      ],
      "metadata": {
        "id": "WpZSm_LrDXvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **99. Working History**"
      ],
      "metadata": {
        "id": "7QDh1xX_Co0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 2024.12.16 ---- Rewrite the prompt in SystemMessage(GPT4_generate_persona)"
      ],
      "metadata": {
        "id": "KeyMuE7ICzAT"
      }
    }
  ]
}